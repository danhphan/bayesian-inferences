{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"data/iris.csv\")\n",
    "y = pd.Categorical(iris['species']).codes\n",
    "x_n = iris.columns[:-1]\n",
    "x = iris[x_n].values\n",
    "# x_s = (x_s - x_s.mean(axis=0)) / x_s.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# m: number of samples\n",
    "# n: number of features\n",
    "# k: number of output labels\n",
    "m, n = x.shape\n",
    "k = 3\n",
    "\n",
    "\n",
    "W = np.zeros(shape=(n,k))\n",
    "b = np.zeros(shape=(1,k))\n",
    "\n",
    "# z = XW + b\n",
    "z = np.dot(x, W) + b\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09003057, 0.24472847, 0.66524096],\n",
       "       [0.33333333, 0.33333333, 0.33333333]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "z1 = np.array([[1, 2, 3], [5, 5, 5]])\n",
    "softmax(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = softmax(z)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(probs, axis=1)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropyLoss(probabilities, target):\n",
    "    \"\"\"Calculates cross entropy loss for a set of predictions and actual targets.\n",
    "    \n",
    "    Args-\n",
    "        predictions- Probability predictions, as returned by multinomialLogReg function\n",
    "        target- Actual target values\n",
    "    Returns- \n",
    "        CELoss- Average cross entropy loss\n",
    "    \"\"\"\n",
    "    n_samples = probabilities.shape[0]\n",
    "    CELoss = 0\n",
    "    for sample, i in zip(probabilities, target):\n",
    "        CELoss += -np.log(sample[i])\n",
    "    CELoss /= n_samples\n",
    "    return CELoss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.098612288668108"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossEntropyLoss(probs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  -  1.098612288668108\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "# X: m*n\n",
    "# W: n*k\n",
    "# y: m*1\n",
    "\n",
    "num_iters = 3\n",
    "lr = 0.01\n",
    "W = np.zeros((n, k))\n",
    "b = np.zeros((1, k))\n",
    "\n",
    "\n",
    "for i in range(num_iters):\n",
    "\n",
    "    z = np.dot(x, W) + b\n",
    "    y_probs = softmax(z)\n",
    "\n",
    "    # calculate lost and gradients\n",
    "    loss = crossEntropyLoss(y_probs, y)\n",
    "    # # back prop / gradient calculations\n",
    "    dW = y_probs.T.dot(x)\n",
    "    db = np.sum(y_probs, axis=0).reshape(-1,1)\n",
    "\n",
    "    W -= lr * dW.T   \n",
    "    b -= lr * db.T\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i, \" - \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.5, -1.5, -1.5]]),\n",
       " array([[-8.765, -8.765, -8.765],\n",
       "        [-4.586, -4.586, -4.586],\n",
       "        [-5.637, -5.637, -5.637],\n",
       "        [-1.799, -1.799, -1.799]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
